{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# PySpark Data Processing and Classification\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the use of **PySpark** for data processing and machine learning tasks. It includes examples of processing an e-commerce dataset and training a Decision Tree Classifier on the Iris dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Dependencies\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!pip install pyspark\\n\",\n",
    "    \"import pyspark\\n\",\n",
    "    \"from pyspark.sql import *\\n\",\n",
    "    \"from pyspark.sql.functions import *\\n\",\n",
    "    \"from pyspark import SparkContext, SparkConf\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the session\\n\",\n",
    "    \"conf = SparkConf().set(\\\"spark.ui.port\\\", \\\"4050\\\")\\n\",\n",
    "    \"sc = pyspark.SparkContext(conf=conf)\\n\",\n",
    "    \"spark = SparkSession.builder.getOrCreate()\\n\",\n",
    "    \"spark\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Download and Load Digikala Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!wget https://bigdata-ir.com/wp-content/uploads/2020/12/digikala_datasetwww.bigdata-ir.com_.zip\\n\",\n",
    "    \"!unzip digikala_datasetwww.bigdata-ir.com_.zip\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"os.rename('digikala_dataset[www.bigdata-ir.com]', 'digikala_dataset')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Load and Explore Orders Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"orders_df = spark.read.csv(\\\"digikala_dataset/orders.csv\\\" , header=True, inferSchema=True)\\n\",\n",
    "    \"orders_df.printSchema()\\n\",\n",
    "    \"orders_df.show(10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Drop Unnecessary Columns\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"orders_df = orders_df.drop('Amount_Gross_Order', 'city_name_fa', 'Quantity_item')\\n\",\n",
    "    \"orders_df.show(5)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Load and Process Purchase History\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"tarikhe_kharid_df = spark.read.csv(\\\"digikala_dataset/tarikhche kharid.csv\\\" , header=True)\\n\",\n",
    "    \"tarikhe_kharid_df = tarikhe_kharid_df.select('id', 'selling_price', 'product_id')\\n\",\n",
    "    \"tarikhe_kharid_df.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Join Datasets\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"join_df = orders_df.join(tarikhe_kharid_df, orders_df.ID_Item == tarikhe_kharid_df.product_id)\\n\",\n",
    "    \"join_df.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Group and Find Popular Products\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"orders_count = join_df.groupBy('product_id').count()\\n\",\n",
    "    \"most_popular = orders_count.orderBy(desc('count')).first()\\n\",\n",
    "    \"most_popular\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Iris Dataset: Decision Tree Classifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from pyspark.ml.feature import StringIndexer, VectorAssembler\\n\",\n",
    "    \"from pyspark.ml.classification import DecisionTreeClassifier\\n\",\n",
    "    \"from pyspark.ml.evaluation import MulticlassClassificationEvaluator\\n\",\n",
    "    \"from pyspark import SparkFiles\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load the Iris dataset\\n\",\n",
    "    \"url = \\\"https://raw.githubusercontent.com/selva86/datasets/master/Iris.csv\\\"\\n\",\n",
    "    \"spark.sparkContext.addFile(url)\\n\",\n",
    "    \"df = spark.read.csv(\\\"file://\\\" + SparkFiles.get(\\\"Iris.csv\\\"), header=True, inferSchema=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Preprocess Data\\n\",\n",
    "    \"label_indexer = StringIndexer(inputCol=\\\"Species\\\", outputCol=\\\"label\\\")\\n\",\n",
    "    \"data = label_indexer.fit(df).transform(df)\\n\",\n",
    "    \"assembler = VectorAssembler(inputCols=[\\\"SepalLengthCm\\\", \\\"SepalWidthCm\\\", \\\"PetalLengthCm\\\", \\\"PetalWidthCm\\\"], outputCol=\\\"features\\\")\\n\",\n",
    "    \"data = assembler.transform(data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split Data\\n\",\n",
    "    \"train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Model\\n\",\n",
    "    \"dt_classifier = DecisionTreeClassifier(labelCol=\\\"label\\\", featuresCol=\\\"features\\\")\\n\",\n",
    "    \"model = dt_classifier.fit(train_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate Model\\n\",\n",
    "    \"predictions = model.transform(test_data)\\n\",\n",
    "    \"evaluator = MulticlassClassificationEvaluator(labelCol=\\\"label\\\", predictionCol=\\\"prediction\\\", metricName=\\\"accuracy\\\")\\n\",\n",
    "    \"accuracy = evaluator.evaluate(predictions)\\n\",\n",
    "    \"print(f\\\"Test Accuracy: {accuracy:.2f}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
